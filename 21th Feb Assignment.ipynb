{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d6be8b-3232-4934-99d6-a1280b00cbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer of Q1 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33dc533-57e6-4577-82f9-bffcb9f03bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Web Scraping :\n",
    "    Web scraping is a automated process of extracting data from websites.\n",
    "\n",
    "Uses :\n",
    "    1. It allows to gather data from a website.\n",
    "    2. It is also used for research and data analysis.\n",
    "    3. By using this method, one can extract email address and used for marketing purpose.\n",
    "    4. It may used in marketing purpose.\n",
    "    5. It enables organzation to monitor their competitor's activity.\n",
    "    \n",
    "    \n",
    "Three areas where Web Scraping is used to get data :\n",
    "    1. Data analysis and academic research :\n",
    "        Web Scraping is used for data analysis that may used in real estate, automobiles etc.\n",
    "        It allows to gather multiple data for research purpose.\n",
    "    2. E-commerce :\n",
    "        It can be used in E-commerce sector.\n",
    "        It is used to collect information from E-commerce websites like Amazon, Flipkart, Myntra etc.\n",
    "    3. Marketing :\n",
    "        The data is used for marketing purpose.\n",
    "        For example :\n",
    "            business contact details, phone number, email address can be scraped from websites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8103f4a5-56bc-4d0c-990a-30b71dc7838b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer of Q2 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bff184e-acdc-4f38-a060-5aa31f0bc5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Different methods used for Web Scraping :\n",
    "    1. Copy and paste :\n",
    "        The most common methods is used for scraping is copying and pasting data from a web page.\n",
    "    2. Text pattern matching :\n",
    "        To extract information from a web page can be done by text pattern matching for Python.\n",
    "    3. HTML :\n",
    "        Websites have large data or information.\n",
    "        Sometime, same type data is collected in same page.\n",
    "        To detect those files are using wrapper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6075ab05-9ac8-43f9-85e1-a85f5fbdb07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer of Q3 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e49fffb-f750-4e35-80d1-4ec01b2be5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "BeautifulSoup :\n",
    "    BeautifulSoup is a popular Python library used for beautifying the data during Web Scraping.\n",
    "    It provide the interface to make complex data into simple data.\n",
    "    \n",
    "Code for BeautifulSoup :\n",
    "    b = bs(variable_file,\"html.parser\")\n",
    "    \n",
    "Uses :\n",
    "    1. Simple API :\n",
    "        It provide a simple, easy-to-use API.\n",
    "        It just simply beautify the data.\n",
    "    2. Data extraction and manipulation :\n",
    "        It also allow for searching, filtering, and manipulating HTML elements.\n",
    "        It allows to modify, remove and add new data or information.\n",
    "    3. Powerful tag :\n",
    "        It used to having powerful tags that used to locate elements based on tag names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ba528d-96fe-4b20-b1ba-e98807053f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer of Q4 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7218c74-a5df-419a-b423-4420b337862f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Flask used in this Web Scraping project :\n",
    "    1. Web interface :\n",
    "        Flask allows to create a web interface for web scraping project.\n",
    "        Flask simply make it easy to create a user-friendly interface for web scraping.\n",
    "    2. Integrate with Data storage :\n",
    "        It integrates with various data storage system and database like MongoDB, AWS.\n",
    "    3. Integrate with Libraries :\n",
    "        It allows to integrate with different libraries like BeautifulSoap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38512a71-4820-4b97-89e0-8d881fe238d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer of Q5 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6151229-ca75-4513-8444-ed7795afca8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "AWS services used in this project :\n",
    "    1. CodePipeline :\n",
    "        CodePipeline is a continuous delivery service that enables to model, visualize, and automate the steps required to release software.\n",
    "        Uses :\n",
    "            It can took data from Github and pass into Beanstalk for run the code.\n",
    "            It also allow to testing action in pipeline to verify the code.\n",
    "            It helps to automate the release process and reduce the human error.\n",
    "    2. Beanstalk :\n",
    "        It is a platform provided by AWS to run the code that is released from CodePipeline.\n",
    "        Uses :\n",
    "            It allow to manage the code very quickly and easily without humna error.\n",
    "            It allow to create multiple stages during running the code."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
